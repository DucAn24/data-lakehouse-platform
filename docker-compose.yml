x-airflow-common:
  &airflow-common
  # In order to add custom dependencies or upgrade provider distributions you can use your extended image.
  # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml
  # and uncomment the "build" line below, Then run `docker-compose build` to build the images.
  # image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:3.1.0}
  build:
    context: ./configs/airflow
    dockerfile: airflow.Dockerfile
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres:5432/airflow
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__EXECUTION_API_SERVER_URL: 'http://airflow-apiserver:8080/execution/'
    # yamllint disable rule:line-length
    # Use simple http server on scheduler for health checks
    # See https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/check-health.html#scheduler-health-check-server
    # yamllint enable rule:line-length
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    # WARNING: Use _PIP_ADDITIONAL_REQUIREMENTS option ONLY for a quick checks
    # for other purpose (development, test and especially production usage) build/extend Airflow image.
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
    # The following line can be used to set a custom config file, stored in the local config folder
    AIRFLOW_CONFIG: '/opt/airflow/config/airflow.cfg'
    # Optimize Airflow for lower resource usage
    AIRFLOW__CORE__PARALLELISM: '8'
    AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG: '6'
    AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: '1'
    AIRFLOW__SCHEDULER__PARSING_PROCESSES: '1'
    AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL: '60'
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./airflow/config:/opt/airflow/config
    - ./spark-jobs:/opt/airflow/spark_jobs
  user: "${AIRFLOW_UID:-50000}:0"
  deploy:
    resources:
      limits:
        cpus: '2.0'
        memory: 2G
  networks:
    - lakehouse-network
  depends_on:
    &airflow-common-depends-on
    postgres:
      condition: service_healthy

services:

  kafka:
    image: apache/kafka:4.0.0
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"  
      - "9093:9093"   
      - "29092:29092" 
    environment:
      # KRaft Configuration
      - KAFKA_KRAFT_MODE=true
      - KAFKA_PROCESS_ROLES=controller,broker
      - KAFKA_NODE_ID=1
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:29092
      - KAFKA_CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qg

      # Listener Configuration
      - KAFKA_LISTENERS=INTERNAL://:9092,EXTERNAL://:9093,CONTROLLER://:29092
      - KAFKA_ADVERTISED_LISTENERS=INTERNAL://kafka:9092,EXTERNAL://localhost:9093
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER

      # Storage Configuration
      - KAFKA_LOG_DIRS=/var/lib/kafka/data

      # Topic Configuration
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE= true
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      
      # JVM Heap Settings for Local Development
      - KAFKA_HEAP_OPTS=-Xms256m -Xmx512m

    volumes:
      - kafka-data:/var/lib/kafka/data
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - lakehouse-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    hostname: kafka-ui
    container_name: kafka-ui
    ports:
      - "8085:8080"  
    environment:
      KAFKA_CLUSTERS_0_NAME: lakehouse-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    networks:
      - lakehouse-network
    depends_on:
      - kafka
    restart: unless-stopped

  kafka-init:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka-init
    depends_on:
      - kafka
    command: >
      bash -c "
        echo 'Waiting for Kafka to be ready...'
        sleep 10
        
        echo 'Creating Kafka Connect topics...'
        kafka-topics --bootstrap-server kafka:9092 \
          --create --if-not-exists \
          --topic _connect-configs \
          --partitions 1 \
          --replication-factor 1 \
          --config cleanup.policy=compact
        
        kafka-topics --bootstrap-server kafka:9092 \
          --create --if-not-exists \
          --topic _connect-offsets \
          --partitions 3 \
          --replication-factor 1 \
          --config cleanup.policy=compact
        
        kafka-topics --bootstrap-server kafka:9092 \
          --create --if-not-exists \
          --topic _connect-status \
          --partitions 3 \
          --replication-factor 1 \
          --config cleanup.policy=compact
        
        echo 'âœ“ Kafka topics created successfully'
      "
    networks:
      - lakehouse-network
    restart: "no"

  kafka-connect:
    image: debezium/connect:3.0.0.Final
    container_name: kafka-connect
    ports:
      - "8086:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: kafka-connect-group
      CONFIG_STORAGE_TOPIC: _connect-configs
      OFFSET_STORAGE_TOPIC: _connect-offsets
      STATUS_STORAGE_TOPIC: _connect-status
      CONFIG_STORAGE_REPLICATION_FACTOR: 1
      OFFSET_STORAGE_REPLICATION_FACTOR: 1
      STATUS_STORAGE_REPLICATION_FACTOR: 1
      KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      ENABLE_DEBEZIUM_SCRIPTING: "true"
      # Reduce heap for local development
      KAFKA_HEAP_OPTS: "-Xms256m -Xmx512m"
    volumes:
      - kafka-connect-data:/var/lib/kafka/connect
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 768M
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - lakehouse-network
    depends_on:
      - kafka
      - kafka-init
      - postgres
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/connectors"]
      interval: 30s
      timeout: 10s
      retries: 5

  postgres:
    image: postgres:16
    hostname: postgres
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: ecommerce
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_REPLICA_IDENTITY: FULL
    command: ["postgres", "-c", "wal_level=logical", "-c", "max_wal_senders=10", "-c", "max_replication_slots=10"]
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./sql/init:/docker-entrypoint-initdb.d
    networks:
      - lakehouse-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  minio:
    image: minio/minio:RELEASE.2025-07-23T15-54-02Z
    hostname: minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password123
      MINIO_BROWSER_REDIRECT_URL: http://localhost:9001
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    networks:
      - lakehouse-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  metastore-db:
    image: postgres:16-alpine
    hostname: metastore-db
    container_name: metastore-db
    ports:
      - "5434:5432"
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive123
    volumes:
      - metastore-db-data:/var/lib/postgresql/data
    networks:
      - lakehouse-network
    restart: unless-stopped

  hive-metastore:
    build:
      context: ./configs/hive
      dockerfile: hive-metastore.Dockerfile
    hostname: hive-metastore
    container_name: hive-metastore
    depends_on:
      - metastore-db
      - minio
    environment:
      # Database Configuration
      DB_DRIVER: postgres
      SERVICE_NAME: metastore
      SERVICE_OPTS: "-Xmx512m -Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://metastore-db:5432/metastore -Djavax.jdo.option.ConnectionUserName=hive -Djavax.jdo.option.ConnectionPassword=hive123"
      
      # S3/MinIO Configuration
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: password123
      S3_ENDPOINT: http://minio:9000
      S3_PATH_STYLE_ACCESS: "true"
      
      # Hadoop Configuration
      HADOOP_CONF_DIR: /opt/hive/conf
      HIVE_CONF_DIR: /opt/hive/conf
      
      # JVM Options for S3A (with reduced heap)
      HADOOP_OPTS: "-Xms128m -Xmx512m -Dfs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem -Dfs.s3a.endpoint=http://minio:9000 -Dfs.s3a.access.key=admin -Dfs.s3a.secret.key=password123 -Dfs.s3a.path.style.access=true"
    ports:
      - "9083:9083"
    volumes:
      - ./configs/hive/hive-site.xml:/opt/hive/conf/hive-site.xml:ro
      - ./configs/hive/core-site.xml:/opt/hive/conf/core-site.xml:ro
      - ./configs/hive/log4j.properties:/opt/hive/conf/log4j.properties:ro
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 768M
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - lakehouse-network
    healthcheck:
      test: ["CMD-SHELL", "netstat -tuln | grep :9083 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  spark-master:
    build:
      context: .
      dockerfile: configs/spark/spark.Dockerfile
    container_name: spark-master
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./spark-jobs:/opt/spark/jobs
      - spark-data:/opt/spark/data
      - ./configs/spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    networks:
      - lakehouse-network
    restart: unless-stopped

  spark-worker-1:
    build:
      context: .
      dockerfile: configs/spark/spark.Dockerfile
    hostname: spark-worker-1
    container_name: spark-worker-1
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_PORT=8881
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
    depends_on:
      - spark-master
    volumes:
      - ./spark-jobs:/opt/spark/jobs
      - spark-data:/opt/spark/data
      - ./configs/spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    networks:
      - lakehouse-network
    restart: unless-stopped

  spark-worker-2:
    build:
      context: .
      dockerfile: configs/spark/spark.Dockerfile
    hostname: spark-worker-2
    container_name: spark-worker-2
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_PORT=8881
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
    depends_on:
      - spark-master
    volumes:
      - ./spark-jobs:/opt/spark/jobs
      - spark-data:/opt/spark/data
      - ./configs/spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    networks:
      - lakehouse-network
    restart: unless-stopped
  
  # trino-coordinator:
  #   image: trinodb/trino:475
  #   hostname: trino-coordinator
  #   container_name: trino-coordinator
  #   ports:
  #     - "8083:8080"  
  #   environment:
  #     - TRINO_ENVIRONMENT=production
  #   volumes:
  #     - ./configs/trino/coordinator-config.properties:/etc/trino/config.properties:ro
  #     - ./configs/trino/coordinator-node.properties:/etc/trino/node.properties:ro
  #     - ./configs/trino/jvm.config:/etc/trino/jvm.config:ro
  #     - ./configs/trino/catalog:/etc/trino/catalog:ro
  #   networks:
  #     - lakehouse-network
  #   depends_on:
  #     - hive-metastore
  #   restart: unless-stopped

  # trino-worker:
  #   image: trinodb/trino:475
  #   hostname: trino-worker
  #   environment:
  #     - TRINO_ENVIRONMENT=production
  #   volumes:
  #     - ./configs/trino/worker-config.properties:/etc/trino/config.properties:ro
  #     - ./configs/trino/worker-node.properties:/etc/trino/node.properties:ro
  #     - ./configs/trino/jvm.config:/etc/trino/jvm.config:ro
  #     - ./configs/trino/catalog:/etc/trino/catalog:ro
  #   networks:
  #     - lakehouse-network
  #   depends_on:
  #     - trino-coordinator
  #   restart: unless-stopped

  postgres-data-loader:
    build:
      context: .
      dockerfile: configs/python/python.Dockerfile
    container_name: postgres-data-loader
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: ecommerce
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - ./scripts:/app/scripts
      - ./data:/app/data
    networks:
      - lakehouse-network
    depends_on:
      postgres:
        condition: service_healthy
    command: tail -f /dev/null

  # chatbot-api:
  #   build:
  #     context: .
  #     dockerfile: configs/python/python.Dockerfile
  #   container_name: chatbot-api
  #   ports:
  #     - "5000:5000"
  #   volumes:
  #     - ./fastapi:/app
  #   networks:
  #     - lakehouse-network
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 30s
  #   command: tail -f /dev/null

  # streamlit:
  #   build:
  #     context: .
  #     dockerfile: configs/streamlit/streamlit.Dockerfile
  #   container_name: lakehouse-streamlit
  #   ports:
  #     - "8501:8501"
  #   volumes:
  #     - ./streamlit:/app
  #   networks:
  #     - lakehouse-network
  #   depends_on:
  #     chatbot-api:
  #       condition: service_started
  #   environment:
  #     - FASTAPI_URL=http://chatbot-api:5000
  #     - OPENAI_API_KEY=${OPENAI_API_KEY:-your_openai_api_key_here}
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 60s
  #   restart: unless-stopped

  # metabase:
  #   image: metabase/metabase:v0.56.10
  #   hostname: metabase
  #   container_name: metabase
  #   environment:
  #     # Database Configuration
  #     MB_DB_TYPE: postgres
  #     MB_DB_DBNAME: metabase
  #     MB_DB_PORT: 5432
  #     MB_DB_USER: metabase
  #     MB_DB_PASS: metabase
  #     MB_DB_HOST: metabase-db
      
  #     # Metabase Settings
  #     MB_JETTY_HOST: 0.0.0.0
  #     MB_JETTY_PORT: 3000
  #     MB_PASSWORD_COMPLEXITY: normal
  #     MB_PASSWORD_LENGTH: 6
  #   ports:
  #     - "3000:3000"
  #   volumes:
  #     - metabase-data:/metabase-data
  #   networks:
  #     - lakehouse-network
  #   depends_on:
  #     metabase-db:
  #       condition: service_healthy
  #     trino-coordinator:
  #       condition: service_started
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 120s
  #   restart: unless-stopped

  # metabase-db:
  #   image: postgres:16-alpine
  #   hostname: metabase-db
  #   container_name: metabase-db
  #   environment:
  #     POSTGRES_DB: metabase
  #     POSTGRES_USER: metabase
  #     POSTGRES_PASSWORD: metabase
  #   volumes:
  #     - metabase-db-data:/var/lib/postgresql/data
  #   networks:
  #     - lakehouse-network
  #   healthcheck:
  #     test: ["CMD", "pg_isready", "-U", "metabase"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #   restart: unless-stopped

  # airflow-dag-processor:
  #   <<: *airflow-common
  #   command: dag-processor
  #   healthcheck:
  #     test: ["CMD-SHELL", 'airflow jobs check --job-type DagProcessorJob --hostname "$${HOSTNAME}"']
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 30s
  #   restart: always
  #   depends_on:
  #     <<: *airflow-common-depends-on
  #     airflow-init:
  #       condition: service_completed_successfully

  # airflow-postgres:
  #   image: postgres:16-alpine
  #   container_name: airflow-postgres
  #   environment:
  #     POSTGRES_USER: airflow
  #     POSTGRES_PASSWORD: airflow
  #     POSTGRES_DB: airflow
  #   ports:
  #     - "5433:5432"
  #   volumes:
  #     - airflow-postgres-data:/var/lib/postgresql/data
  #   healthcheck:
  #     test: ["CMD", "pg_isready", "-U", "airflow"]
  #     interval: 10s
  #     retries: 5
  #     start_period: 5s
  #   restart: always
  #   networks:
  #     - lakehouse-network

  # airflow-apiserver:
  #   <<: *airflow-common
  #   command: api-server
  #   ports:
  #     - "8081:8080"
  #   healthcheck:
  #     test: ["CMD", "curl", "--fail", "http://localhost:8081/api/v2/version"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 30s
  #   restart: always
  #   depends_on:
  #     <<: *airflow-common-depends-on
  #     airflow-init:
  #       condition: service_completed_successfully

  # airflow-scheduler:
  #   <<: *airflow-common
  #   command: scheduler
  #   healthcheck:
  #     test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 30s
  #   restart: always
  #   depends_on:
  #     <<: *airflow-common-depends-on
  #     airflow-init:
  #       condition: service_completed_successfully

  # airflow-init:
  #   <<: *airflow-common
  #   entrypoint: /bin/bash
  #   # yamllint disable rule:line-length
  #   command:
  #     - -c
  #     - |
  #       if [[ -z "${AIRFLOW_UID}" ]]; then
  #         echo
  #         echo -e "\033[1;33mWARNING!!!: AIRFLOW_UID not set!\e[0m"
  #         echo "If you are on Linux, you SHOULD follow the instructions below to set "
  #         echo "AIRFLOW_UID environment variable, otherwise files will be owned by root."
  #         echo "For other operating systems you can get rid of the warning with manually created .env file:"
  #         echo "    See: https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#setting-the-right-airflow-user"
  #         echo
  #         export AIRFLOW_UID=$(id -u)
  #       fi
  #       one_meg=1048576
  #       mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))
  #       cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)
  #       disk_available=$$(df / | tail -1 | awk '{print $$4}')
  #       warning_resources="false"
  #       if (( mem_available < 4000 )) ; then
  #         echo
  #         echo -e "\033[1;33mWARNING!!!: Not enough memory available for Docker.\e[0m"
  #         echo "At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))"
  #         echo
  #         warning_resources="true"
  #       fi
  #       if (( cpus_available < 2 )); then
  #         echo
  #         echo -e "\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\e[0m"
  #         echo "At least 2 CPUs recommended. You have $${cpus_available}"
  #         echo
  #         warning_resources="true"
  #       fi
  #       if (( disk_available < one_meg * 10 )); then
  #         echo
  #         echo -e "\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\e[0m"
  #         echo "At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))"
  #         echo
  #         warning_resources="true"
  #       fi
  #       if [[ $${warning_resources} == "true" ]]; then
  #         echo
  #         echo -e "\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\e[0m"
  #         echo "Please follow the instructions to increase amount of resources available:"
  #         echo "   https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#before-you-begin"
  #         echo
  #       fi
  #       echo
  #       echo "Creating missing opt dirs if missing:"
  #       echo
  #       mkdir -v -p /opt/airflow/{logs,dags,plugins,config}
  #       echo
  #       echo "Airflow version:"
  #       /entrypoint airflow version
  #       echo
  #       echo "Files in shared volumes:"
  #       echo
  #       ls -la /opt/airflow/{logs,dags,plugins,config}
  #       echo
  #       echo "Running airflow config list to create default config file if missing."
  #       echo
  #       /entrypoint airflow config list >/dev/null
  #       echo
  #       echo "Files in shared volumes:"
  #       echo
  #       ls -la /opt/airflow/{logs,dags,plugins,config}
  #       echo
  #       echo "Change ownership of files in /opt/airflow to ${AIRFLOW_UID}:0"
  #       echo
  #       chown -R "${AIRFLOW_UID}:0" /opt/airflow/
  #       echo
  #       echo "Change ownership of files in shared volumes to ${AIRFLOW_UID}:0"
  #       echo
  #       chown -v -R "${AIRFLOW_UID}:0" /opt/airflow/{logs,dags,plugins,config}
  #       echo
  #       echo "Files in shared volumes:"
  #       echo
  #       ls -la /opt/airflow/{logs,dags,plugins,config}

  #   # yamllint enable rule:line-length
  #   environment:
  #     <<: *airflow-common-env
  #     _AIRFLOW_DB_MIGRATE: 'true'
  #     _AIRFLOW_WWW_USER_CREATE: 'true'
  #     _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
  #     _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
  #     _PIP_ADDITIONAL_REQUIREMENTS: ''
  #   user: "0:0"

volumes:
  kafka-data:
  postgres-data:
  minio-data:
  metastore-db-data:
  spark-data:
  metabase-db-data:
  metabase-data:
  airflow-postgres-data:
  kafka-connect-data:
  
networks:
  lakehouse-network:
    name: lakehouse-network

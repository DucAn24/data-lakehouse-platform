# Delta Lake extensions
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog

# S3/MinIO configuration
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.access.key=admin
spark.hadoop.fs.s3a.secret.key=password123
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.fast.upload=true
spark.hadoop.fs.s3a.create.bucket=true 
spark.hadoop.fs.s3a.connection.ssl.enabled=false
spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider 


# Performance settings 
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true
spark.sql.adaptive.skewJoin.enabled=true
spark.sql.adaptive.localShuffleReader.enabled=true
spark.serializer=org.apache.spark.serializer.KryoSerializer

# Delta Lake support
spark.sql.catalog.delta=org.apache.spark.sql.delta.catalog.DeltaCatalog

# Hive Metastore
spark.sql.catalogImplementation=hive
spark.hadoop.hive.metastore.uris=thrift://hive-metastore:9083

# # Elasticsearch connector
# spark.es.nodes=elasticsearch
# spark.es.port=9200
# spark.es.nodes.wan.only=true
